{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.arange(1, 4)\n",
        "y = np.array([2,4,6])\n",
        "np.sum(x*x)*0.5*np.sum(y*y)*0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrhRInFPxuFM",
        "outputId": "d1aa2f66-d4ac-4311-bac5-3d74e1e985d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196.0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwiqYpIg4CkE",
        "outputId": "6659b795-78c1-4165-da35-096fd3f44135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKSGnXEB4Eua",
        "outputId": "1debdc67-c0d7-4566-e684-d0f32e16627f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHFS0Xjv7AMj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def load_dataset():\n",
        "    # Load dataset\n",
        "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "    # Reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "    trainX = np.where(trainX > 0, 255, 0)\n",
        "    testX = np.where(testX > 0, 255, 0)\n",
        "    # One-hot encode target values\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "    return trainX, trainY, testX, testY\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "    # Convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # Normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def define_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', input_shape=(28, 28, 1), padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def run():\n",
        "    # Load dataset\n",
        "    trainX, trainY, testX, testY = load_dataset()\n",
        "    # Prepare pixel data\n",
        "    trainX, testX = prep_pixels(trainX, testX)\n",
        "    # Define model\n",
        "    model = define_model()\n",
        "\n",
        "    # Create data generator\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        shear_range=0.3,\n",
        "        zoom_range=0.3,\n",
        "        horizontal_flip=False,\n",
        "        brightness_range=[0., 1.5]\n",
        "    )\n",
        "\n",
        "    # Fit model\n",
        "    model.fit(datagen.flow(trainX, trainY, batch_size=128), epochs=10, validation_data=datagen.flow(testX, testY), verbose=1)\n",
        "    # Save model\n",
        "    model.save('final_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l-I9FD7n7LO3"
      },
      "outputs": [],
      "source": [
        "run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ozJabdS_7Luo"
      },
      "outputs": [],
      "source": [
        "def create_dataset_from_folder(folder):\n",
        "    images = []\n",
        "    filenames = []\n",
        "    def load_image(filename):\n",
        "        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "          return None\n",
        "        img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
        "        img = img.reshape(28, 28, 1)\n",
        "        copy = img.copy()\n",
        "        mean = cv2.mean(copy)[0]\n",
        "        if mean < 100:\n",
        "          img[copy > mean] = 255\n",
        "          img[copy <= mean] = 0\n",
        "        else:\n",
        "          img[copy > mean] = 0\n",
        "          img[copy <= mean] = 255\n",
        "        img = img.astype('float32') / 255.0\n",
        "        return img\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        filepath = os.path.join(folder, filename)\n",
        "        img = load_image(filepath)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            filenames.append(filename)\n",
        "\n",
        "    return filenames, np.array(images)\n",
        "\n",
        "def save_predictions_to_csv(filenames, predictions, csv_filename):\n",
        "    with open(csv_filename, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for filename, prediction in zip(filenames, predictions):\n",
        "            writer.writerow([filename, prediction])\n",
        "\n",
        "model = load_model('final_model.h5')\n",
        "\n",
        "root_folder = './data'\n",
        "filenames, test_dataset = create_dataset_from_folder(root_folder)\n",
        "\n",
        "predictions = model.predict(test_dataset)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "csv_filename = 'submission.csv'\n",
        "save_predictions_to_csv(filenames, predicted_labels, csv_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lx-rqeqkBqBS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(28, 28))\n",
        "start = 1000\n",
        "end = 1090\n",
        "for i in range(start, end):\n",
        "    plt.subplot(30, 3, i - start + 1)\n",
        "    plt.imshow(test_dataset[i], cmap='gray')\n",
        "    plt.title(f\"predict: {predicted_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}